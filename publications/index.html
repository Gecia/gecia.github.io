<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Gecia Bravo-Hermsdorff | Publications [<a href="https://scholar.google.com/citations?user=Jq9GtykAAAAJ" target="_blank">Google Scholar</a>]</title>
  <meta name="description" content="Gecia Bravo-Hermsdorff 
">

  

  <link rel="shortcut icon" href="/assets/img/favicon.ico">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/publications/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <strong>Gecia</strong> Bravo-Hermsdorff
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="/">Home</a>

        <!-- Blog -->
<!--         <a class="page-link" href="/blog/">blog</a> -->

        <!-- Pages -->
        
          
        
          
<!--             <a class="page-link" href="/projects/">Projects</a> -->
          
        
          
            <a class="page-link" href="/publications/">Publications</a>
          
        
          
        
          
        

        <!-- CV link -->
        <a class="page-link" href="/assets/pdf/CV_GeciaBravoHermsdorff.pdf">CV</a>

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Publications</h1>
    <h5 class="post-description"><i>*denotes equal contribution.</i></h5>
  </header>

  <article class="post-content Publications clearfix">

    <h3 class="year">2025</h3>
<ol class="bibliography"><li>

      <div id="causalgrowinggraphs2025">
    <span class="title">Causal Models for Growing Networks</span>
    <span class="author">
    <em>Gecia Bravo-Hermsdorff</em>, Kayvan Sadeghi, and Lee M. Gunderson

    </span>

    <span class="periodical">
    
      <em>In 41st Conference on Uncertainty in Artificial Intelligence (UAI), </em>
    
    
      2025
    
    </span>
  

  <span class="links">

<!--    -->
  
    [<a class="abstract">Abstract</a>]
  
  
      [<a href="https://arxiv.org/abs/2504.01012" target="_blank">URL</a>]
    
    
  
    [<a href="https://gecia.github.io/assets/pdf/CausalModelsForGrowingNetworks_arXiv2025.pdf" target="_blank">PDF</a>]
  
    
<!--     [<a href="https://gecia.github.io/assets/pdf/CausalModelsForGrowingNetworks_arXiv2025.pdf" target="_blank">Poster</a>] -->
  
  
  
<!--     [<a href="https://github.com/rbas-ucl/intgen" target="_blank">Code</a>] -->
    
<!--      [<a href="https://www.youtube.com/watch?v=y0KCHT9qy8c&t=623s" target="_blank">Video</a>]      -->
     
  </span>

  <!-- Hidden abstract block -->
    
  <span class="abstract hidden">
    <p> 
      Real-world networks grow over time; statistical models based on node exchangeability are not appropriate. 
      Instead of constraining the structure of the <em>distribution</em> of edges, we propose that the relevant symmetries refer to the <em>causal structure</em> between them. 
      We first enumerate the 96 causal directed acyclic graph (DAG) models over pairs of nodes (dyad variables) in a growing network with finite ancestral sets that are invariant to node deletion. 
      We then partition them into 21 classes with ancestral sets that are closed under node marginalization. 
      Several of these classes are remarkably amenable to distributed and asynchronous evaluation. 
      As an example, we highlight a simple model that exhibits flexible power-law degree distributions and emergent phase transitions in sparsity, which we characterize analytically. 
      With few parameters and much conditional independence, our proposed framework provides natural baseline models for causal inference in relational data.
    </p>
  </span>

   </div>
 </li>
<li>  


    <div id="budgetIV">
    <span class="title">BudgetIV: Optimal Partial Identification of Causal Effects
with Mostly Invalid Instruments</span>
    <span class="author">
     Jordan Penn,  <em>Gecia Bravo-Hermsdorff</em>, Lee M. Gunderson, Ricardo Silva, and David S. Watson

    </span>

    <span class="periodical">
    
      <em>In 28th International Conference on Artificial Intelligence and Statistics (AISTATS), </em>
    
    
      2025
    
    </span>
  

  <span class="links">

<!--    -->
  
    [<a class="abstract">Abstract</a>]
  
  
      [<a href="https://arxiv.org/pdf/2411.06913" target="_blank">URL</a>]
    
    
  [<a href="/assets/pdf/BudgetIV_OptimalPartialIdentificationOfCausalEffectswithMostlyInvalidInstruments_AISTATS2025.pdf" target="_blank">PDF</a>]
  
  
<!--     [<a href="https://cran.r-project.org/web/packages/leakyIV/index.html" target="_blank">Code</a>] -->
    
 
     
  </span>

  <!-- Hidden abstract block -->
    
  <span class="abstract hidden">
    <p> 
Instrumental variables (IVs) are widely used to estimate causal effects in the presence of unobserved confounding between an exposure X and outcome Y. 
An IV must affect Y <em>exclusively</em> through X and be <em>unconfounded</em> with Y. 
We present a framework for relaxing these assumptions with tuneable and interpretable "budget constraints". 
Our algorithm returns a feasible set of causal effects that can be identified exactly given perfect knowledge of observable covariance statistics.
This feasible set might contain disconnected sets of possible solutions for the causal effect. 
We discuss conditions under which this set is <em>sharp</em>, i.e., contains all and only effects consistent with the background assumptions and the joint distribution of observable variables. 
Our method applies to a wide class of semiparametric models, and we demonstrate how its ability to select specific subsets of instruments confers an advantage over convex relaxations in both linear and nonlinear settings. 
We adapt our algorithm to form confidence sets that are asymptotically valid under a common statistical assumption from the Mendelian randomization literature. 
    </p>
  </span>

<!--    </div>
 </li>
<li>   -->

    <!-- </div> -->
    <!-- </ol> -->
  
<!-- </div>
 </li> -->
  
    </div>


    </ol>
    
<h3 class="year">2024</h3>
<ol class="bibliography"><li>


    <div id="leakyIV">
    <span class="title">Bounding Causal Effects with Leaky Instruments</span>
    <span class="author">
     David S. Watson, Jordan Penn, Lee M. Gunderson, <em>Gecia Bravo-Hermsdorff</em>, Afsaneh Mastouri, and Ricardo Silva

    </span>

    <span class="periodical">
    
      <em>In Fortieth Conference on Uncertainty in Artificial Intelligence (UAI), </em>
    
    
      2024
    
    </span>
  

  <span class="links">

<!--    -->
  
    [<a class="abstract">Abstract</a>]
  
  
      [<a href="https://arxiv.org/abs/2404.04446" target="_blank">URL</a>]
    
    
  [<a href="/assets/pdf/BoundingCausalEffectsWithLeakyInstruments_UAI2024.pdf" target="_blank">PDF</a>]
  
  
    [<a href="https://cran.r-project.org/web/packages/leakyIV/index.html" target="_blank">Code</a>]
    
 
     
  </span>

  <!-- Hidden abstract block -->
    
  <span class="abstract hidden">
    <p> 
Instrumental variables (IVs) are a popular and powerful tool for estimating causal effects in the presence of unobserved confounding. 
However, classical approaches rely on strong assumptions such as the exclusion criterion, which states that instrumental effects must be entirely mediated by treatments. 
This assumption often fails in practice. 
When IV methods are improperly applied to data that do not meet the exclusion criterion, estimated causal effects may be badly biased. 
In this work, we propose a novel solution that provides partial identification in linear models given a set of leaky instruments, which are allowed to violate the exclusion criterion to some limited degree. 
We derive a convex optimization objective that provides provably sharp bounds on the average treatment effect under some common forms of information leakage, and implement inference procedures to quantify the uncertainty of resulting estimates. 
We demonstrate our method in a set of experiments with simulated data, where it performs favorably against the state of the art.
    </p>
  </span>

<!--    </div>
 </li>
<li>   -->

    <!-- </div> -->
    <!-- </ol> -->
  
<!-- </div>
 </li> -->


      
  
    </div>


    </ol>




<h3 class="year">2023</h3>
<ol class="bibliography"><li>


    <div id="IFM2023">
    <span class="title">Intervention Generalization: A View from Factor Graph Models</span>
    <span class="author">
    <em>Gecia Bravo-Hermsdorff</em>, David S. Watson, Jialin Yu, Jakob Zeitler, and Ricardo Silva

    </span>

    <span class="periodical">
    
      <em>In Neural Information Processing Systems 37 (NeurIPS), </em>
    
    
      2023
    
    </span>
  

  <span class="links">

<!--    -->
  
    [<a class="abstract">Abstract</a>]
  
  
      [<a href="https://arxiv.org/abs/2306.04027" target="_blank">URL</a>]
    
    
  
    [<a href="/assets/pdf/InterventionGeneralizationAViewFromFactorGraphModels_NeurIPS2023.pdf" target="_blank">PDF</a>]
  
    
    [<a href="/assets/pdf/InterventionalFactorModelsPosterNeurIPS2023.pdf" target="_blank">Poster</a>]
  
  
  
    [<a href="https://github.com/rbas-ucl/intgen" target="_blank">Code</a>]
    
     [<a href="https://www.youtube.com/watch?v=y0KCHT9qy8c&t=623s" target="_blank">Video</a>]     
     
  </span>

  <!-- Hidden abstract block -->
    
  <span class="abstract hidden">
    <p> 
One of the goals of causal inference is to generalize from past experiments and observational data to novel conditions. 
While it is in principle possible to eventually learn a mapping from a novel experimental condition to an outcome of interest, 
provided a sufficient variety of experiments is available in the training data, 
coping with a large combinatorial space of possible interventions is hard. 
Under a typical sparse experimental design, this mapping is ill-posed without relying on heavy regularization or prior distributions. 
Such assumptions may or may not be reliable, and can be hard to defend or test. 
In this paper, we take a close look at how to warrant a leap from past experiments to novel conditions based on minimal assumptions about the factorization of the distribution of the manipulated system, 
communicated in the well-understood language of factor graph models. 
A postulated interventional factor model (IFM) may not always be informative, 
but it conveniently abstracts away a need for explicitly modeling unmeasured confounding and feedback mechanisms, 
leading to directly testable claims. 
Given an IFM and datasets from a collection of experimental regimes, 
we derive conditions for identifiability of the expected outcomes of new regimes never observed in these training data. 
We implement our framework using several efficient algorithms, 
and apply them on a range of semi-synthetic experiments.
    </p>
  </span>

   </div>
 </li>
<li>  
  
  <div id="prony2023">
    <span class="title">The Graph Pencil Method: Mapping Subgraph Densities to Stochastic Block Models</span>
    <span class="author">
    Lee M. Gunderson, <em>Gecia Bravo-Hermsdorff</em>, Peter Orbanz

    </span>

    <span class="periodical">
    
      <em>In Neural Information Processing Systems 37 (NeurIPS), </em>
    
    
      2023
    
    </span>
  

  <span class="links">

<!--    -->
  
    [<a class="abstract">Abstract</a>]
  
  
      [<a href="https://neurips.cc/virtual/2023/poster/70158" target="_blank">URL</a>]
    
    
  
    [<a href="/assets/pdf/TheGraphPencilMethodMappingSubgraphDensitiesToStochasticBlockModels_NeurIPS2023.pdf" target="_blank">PDF</a>]
  
    
        [<a href="/assets/pdf/PairwisePronyPosterNeurIPS2023.pdf" target="_blank">Poster</a>]
  
  
  
    
    
      
     
  </span>

  <!-- Hidden abstract block -->
    
  <span class="abstract hidden">
    <p> 
In this work, we describe a method that determines an exact map from a finite set of subgraph densities to the parameters of a stochastic block model (SBM) matching these densities. 
Given a number K of blocks, the subgraph densities of a finite number of stars and bistars uniquely determines a single element of the class of all degree-separated stochastic block models with K blocks. 
Our method makes it possible to translate estimates of these subgraph densities into model parameters, 
and hence to use subgraph densities directly for inference. 
The computational overhead is negligible; computing the translation map is polynomial in K, 
but independent of the graph size once the subgraph densities are given.

    </p>
  </span>

   </div>
 </li>
<li>  
    

<div id="priorGraphs2023">
    <span class="title">Quantifying Human Priors over Social and Navigation Networks</span>
    <span class="author">
    <em>Gecia Bravo-Hermsdorff</em>

    </span>

    <span class="periodical">
    
      <em>In Fortieth International Conference on Machine Learning (ICML), </em>
    
    
      2023
    
    </span>
  

  <span class="links">

<!--    -->
  
    [<a class="abstract">Abstract</a>]
  
  
      [<a href="https://proceedings.mlr.press/v202/bravo-hermsdorff23a.html" target="_blank">URL</a>]
    
    
  
    [<a href="/assets/pdf/QuantifyingHumanPriorsOverSocialandNavigationNetworks_ICML2023.pdf" target="_blank">PDF</a>]
  
    
            [<a href="/assets/pdf/HumanPriorsPosterICML2023.pdf" target="_blank">Poster</a>]
  
  
      [<a href="https://www.youtube.com/watch?v=aZNeN293MZs&list=PLmfiQcz2q6d2Pws-3T2sJW-j4vH-x9Mrf&index=1" target="_blank">Demo of experimental platform</a>]
    
    
      
     
  </span>

  <!-- Hidden abstract block -->
    
  <span class="abstract hidden">
    <p> 
      Human knowledge is largely implicit and relational — do we have a friend in common? can I walk from here to there? 
      In this work, we leverage the combinatorial structure of graphs to quantify human priors over such relational data. 
      Our experiments focus on two domains that have been continuously relevant over evolutionary timescales: social interaction and spatial navigation. 
      We find that some features of the inferred priors are remarkably consistent, such as the tendency for sparsity as a function of graph size. 
      Other features are domain-specific, such as the propensity for triadic closure in social interactions. 
      More broadly, our work demonstrates how nonclassical statistical analysis of indirect behavioral experiments can be used to efficiently model latent biases in the data.
    </p>
  </span>
  

  
<!-- </div>
 </li> -->
  
    </div>

   </li>
<li>  
  

  <div id="cumulantsJMLR2023">
    <span class="title">Quantifying Network Similarity using Graph Cumulants</span>
    <span class="author">
    <em>Gecia Bravo-Hermsdorff*</em>, Lee M. Gunderson*, Pierre-André Maugis, and Carey E. Priebe

    </span>

    <span class="periodical">
    
      <em>Journal of Machine Learning Research</em>, 24(187):1−27, 
    
    
      2023
    
    </span>
  

  <span class="links">

<!--    -->
  
    [<a class="abstract">Abstract</a>]
  
  
      [<a href="https://www.jmlr.org/papers/v24/21-082.html" target="_blank">URL</a>]
    
    
  
    [<a href="/assets/pdf/QuantifyingNetworkSimilarityUsingGraphCumulants_JMLR2023.pdf" target="_blank">PDF</a>]
  
    
    [<a href="/assets/pdf/QuantifyingNetworkSimilarityUsingGraphCumulantsICRL2024.pdf" target="_blank">Poster</a>]
  
  
  
    
    
      
     
  </span>

  <!-- Hidden abstract block -->
    
  <span class="abstract hidden">
    <p> 
    How might one test the hypothesis that networks were sampled from the same distribution? 
    Here, we compare two statistical tests that use subgraph counts to address this question. 
    The first uses the empirical subgraph densities themselves as estimates of those of the underlying distribution. 
    The second test uses a new approach that converts these subgraph densities into estimates of the graph cumulants of the distribution 
    (without any increase in computational complexity). 
    We demonstrate — via theory, simulation, and application to real data — the superior statistical power of using graph cumulants. 
    In summary, when analyzing data using subgraph/motif densities, we suggest using the corresponding graph cumulants instead.
    </p>
  </span>
  

  
<!-- </div>
 </li> -->
  
    </div>


    </ol>




    
<h3 class="year">2022</h3>
<ol class="bibliography"><li>
  
  <div id="privateentropyestimation2023">
    <span class="title">Private and Communication-Efficient Algorithms for Entropy Estimation</span>
    <span class="author">
    <em>Gecia Bravo-Hermsdorff</em>, Robert Busa-Fekete, Mohammad Ghavamzadeh, Andrés Munõs Medina, and Umar Syed

    </span>

    <span class="periodical">
    
      <em>In Neural Information Processing Systems 36 (NeurIPS), </em>
    
    
      2022
    
    </span>
  

  <span class="links">

<!--    -->
  
    [<a class="abstract">Abstract</a>]
  
  
      [<a href="https://openreview.net/forum?id=OZEmgSbRQW" target="_blank">URL</a>]
    
    
  
    [<a href="/assets/pdf/PrivateAndCommunicationEfficientAlgorithmsforEntropyEstimation_NeurIPS2022_UpdatedVersion.pdf" target="_blank">PDF</a>]
  
    
         [<a href="https://slideslive.com/38990212/private-and-communicationefficient-algorithms-for-entropy-estimation?ref=search-presentations-gecia" target="_blank">Summary video (2m35s)</a>]
  
  
  
    
    
      
     
  </span>

  <!-- Hidden abstract block -->
    
  <span class="abstract hidden">
    <p> 
Modern statistical estimation is often performed in a distributed setting where each sample belongs to a single user who shares their data with a central server. 
      Users are typically concerned with preserving the privacy of their samples, and also with minimizing the amount of data they must transmit to the server. 
      We give improved private and communication-efficient algorithms for estimating several popular measures of the entropy of a distribution. 
      All of our algorithms have constant communication cost and satisfy local differential privacy. 
      For a joint distribution over many variables whose conditional independence given by a tree, we describe algorithms for estimating Shannon entropy that require a number of samples that is linear in the number of variables, compared to the quadratic sample complexity of prior work. 
      We also describe an algorithm for estimating Gini entropy whose sample complexity has no dependence on the support size of the distribution and can be implemented using a single round of concurrent communication between the users and the server. 
      In contrast, the previously best-known algorithm has high communication cost and requires the server to facilitate interaction between the users. 
      Finally, we describe an algorithm for estimating collision entropy that matches the space and sample complexity of the best known algorithm but generalizes it to the private and communication-efficient setting.
    </p>
  </span>

   </div>
 </li>
<li>  
    

<div id="statisticalanonymitybravohermsdorff2022">
    <span class="title">Statistical Anonymity: Quantifying Reidentification Risks Without Reidentifying Users</span>
    <span class="author">
    <em>Gecia Bravo-Hermsdorff</em>, Robert Busa-Fekete, Lee M. Gunderson, Andrés Munõs Medina, and Umar Syed

    </span>

    <span class="periodical">
    
      <em>arXiv preprint, </em>
    
    
      2022
    
    </span>
  

  <span class="links">

<!--    -->
  
    [<a class="abstract">Abstract</a>]
  
  
      [<a href="https://arxiv.org/abs/2201.12306" target="_blank">URL</a>]
    
    
  
    [<a href="/assets/pdf/StatisticalAnonymity2022.pdf" target="_blank">PDF</a>]
  
    
    
  
  
  
    
    
      
     
  </span>

  <!-- Hidden abstract block -->
    
  <span class="abstract hidden">
    <p> 
      Data anonymization is an approach to privacy-preserving data release aimed at preventing participants reidentification, 
      and it is an important alternative to differential privacy in applications that cannot tolerate noisy data. 
      Existing algorithms for enforcing k-anonymity in the released data assume that the curator performing the anonymization has complete access to the original data. 
      Reasons for limiting this access range from undesirability to complete infeasibility. 
      This paper explores ideas -- objectives, metrics, protocols, and extensions -- for reducing the trust that must be placed in the curator, 
      while still maintaining a statistical notion of k-anonymity. 
      We suggest trust (amount of information provided to the curator) and privacy (anonymity of the participants) as the primary objectives of such a framework. 
      We describe a class of protocols aimed at achieving these goals, proposing new metrics of privacy in the process, and proving related bounds. 
      We conclude by discussing a natural extension of this work that completely removes the need for a central curator.
    </p>
  </span>
  

  
<!-- </div>
 </li> -->
  
    </div>
    </ol>
  

  
    
    <h3 class="year">2021</h3>
<ol class="bibliography"><li>

<div id="graphcumulantstestbravohermsdorff2021">
  
    <span class="title">A Principled (and Practical) Test for Network Comparison</span>
    <span class="author">
      
        
          
            
      
      
      
      
              <em>Gecia Bravo-Hermsdorff*</em>, Lee M. Gunderson*, Pierre-André Maugis, and Carey E. Priebe
            
          
        
      
        
          
            
             
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>arXiv preprint, </em>
    
    
      2021
    
    </span>
  

  <span class="links">

<!--    -->
  
    [<a class="abstract">Abstract</a>]
  
  
      [<a href="https://arxiv.org/abs/2107.11403" target="_blank">URL</a>]
    
    
  
    [<a href="/assets/pdf/A principled (and practical) test for network comparison.pdf" target="_blank">PDF</a>]
  
    
    
  
  
  
    
    
      
     
  </span>

  <!-- Hidden abstract block -->
    
  <span class="abstract hidden">
    <p>How might one test the hypothesis that graphs were sampled from the same distribution? 
      Here, we compare two statistical tests that address this question. 
      The first uses the observed subgraph densities themselves as estimates of those of the underlying distribution. 
      The second test uses a new approach that converts these subgraph densities into estimates of the graph cumulants of the distribution. 
      We demonstrate -- via theory, simulation, and application to real data -- the superior statistical power of using graph cumulants.</p>
  </span>
  

  



<!--      -->

<!--      -->
</div>
 </li>
<li> 
  

    
  <div id="bravohermsdorff2021deepsets">
  
    <span class="title">Permutation-Equivariant Neural Networks for Power Spectrum Estimation</span>
    <span class="author">
      
        
          
            
              <em>Gecia Bravo-Hermsdorff</em>
            
          
        
      
        
          
            
              
              
            
          
        
      
        
          
            
              

            
          
        
      
        
          
            
              

            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Informal write-up, </em>
    
    
      2021
    
    </span>
  

  <span class="links">

<!--    -->
  
    [<a class="abstract">Quick summary</a>]
  
  
  
  
    [<a href="/assets/pdf/GoogleAIResidencyMiniProject.pdf" target="_blank">PDF</a>]
  
    
  
  
  
  
 
      
     
  </span>

  <!-- Hidden abstract block -->
    
  <span class="abstract hidden">
    <p>A fun and short introduction (in a form of a dialogue!) to permutation equivariant neural networks,ie, neural networks that don’t care about the order of things. 
      This was my mini-project for the AI residency onboarding program to get familiar with Google’s infrastructure. 
    </p>
  </span>
  

  



<!--      -->

<!--      -->
</div>
    </ol>
  
    
<h3 class="year">2020</h3>
<ol class="bibliography"><li>

<div id="graphcumulantsbravohermsdorff2020">
  
    <span class="title">Introducing Graph Cumulants: What is the Variance of your Social Network?</span>
    <span class="author">
      
        
          
            Lee M. Gunderson* and 
      
      
      
      
              <em>Gecia Bravo-Hermsdorff*</em>
            
          
        
      
        
          
            
             
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>arXiv preprint, </em>
    
    
      2020
    
    </span>
  

  <span class="links">

<!--    -->
  
    [<a class="quickabstract">Quick summary</a>]
  

        [<a class="abstract">Abstract</a>]
    
      [<a href="https://arxiv.org/abs/2002.03959" target="_blank">URL</a>]
    
    
  
    [<a href="/assets/pdf/GraphCumulants_arXiv.pdf" target="_blank">PDF</a>]
  
    
    [<a href="https://www.youtube.com/watch?v=S5jstCYlvYs" target="_blank">Summary video (9m21s)</a>]
  
  
  
              [<a href="https://github.com/TheGravLab/GraphCumulants" target="_blank">Code</a>]
    
      
     
  </span>

  <!-- Hidden abstract block -->
    
  <span class="quickabstract hidden">
    <p>Over a century ago, Thiele (1889) introduced cumulants, a concept now fundamental to the field of statistics, which has justifiably percolated throughout the scientific community. 
      In this work, we introduce graph cumulants, their generalization to networks. 
      This principled hierarchy of network statistics provides a framework to systematically describe and compare networks, 
      naturally including those with additional features, such as directed edges, node attributes, and edge weights. 
      Moreover, through the lens of the maximum entropy principle, these statistics induce a natural hierarchical family of network models. 
      These models are immune to the "degeneracy problem", providing a principled prescription for obtaining distributions 
      that are clustered around the properties of the network they intend to model.</p>
  </span>
  

    <!-- Hidden abstract block -->
    
  <span class="abstract hidden">
    <p>In an increasingly interconnected world, understanding and summarizing the
structure of these networks becomes increasingly relevant. However, this task
is nontrivial; proposed summary statistics are as diverse as the networks
they describe, and a standardized hierarchy has not yet been established.
In contrast, vector-valued random variables admit such a description in
terms of their cumulants (e.g., mean, (co)variance, skew, kurtosis). Here,
we introduce the natural analogue of cumulants for networks, building a
hierarchical description based on correlations between an increasing number
of connections, seamlessly incorporating additional information, such as
directed edges, node attributes, and edge weights. These graph cumulants
provide a principled and unifying framework for quantifying the propensity
of a network to display any substructure of interest (such as cliques to measure
clustering). Moreover, they give rise to a natural hierarchical family of
maximum entropy models for networks (i.e., ERGMs) that do not suffer from
the “degeneracy problem”, a common practical pitfall of other ERGMs.</p>
  </span>
  



<!--      -->

<!--      -->
</div>
</li>
<li>

<div id="bravohermsdorff2020Thesis">
  
    <span class="title">Quantifying Human Priors over Abstract Relational Structures</span>
    <span class="author">
      
        
          
            <em>Gecia Bravo-Hermsdorff</em> 
          
        
      
    </span>

    <span class="periodical">
    
      <em>Ph.D. Dissertation, Princeton University, </em>
    
    
      2020
    
    </span>
  

  <span class="links">

<!--   
    [<a class="abstract">Abstract</a>]
   -->
  
  
  
  
    
  
    
      [<a class="abstract">Abstract</a>]
  
  
        [<a href="https://search.proquest.com/openview/3267abd39a938d954ef3cf1ff35ba211/1?pq-origsite=gscholar&cbl=18750&diss=y">URL</a>]
  
    [<a href="/assets/pdf/GeciaPhDDissertation.pdf" target="_blank">PDF</a>]
    
    [<a href="/assets/pdf/Gecia_FPO_vFinalReduced-compressed.pdf" target="_blank">Slides</a>]
  
  
    
    
    
  [<a href="https://www.youtube.com/playlist?list=PLmfiQcz2q6d2Pws-3T2sJW-j4vH-x9Mrf" target="_blank">Demos of Mturk experiments</a>]
    
     
  </span>

  <!-- Hidden abstract block -->
    

  
  <span class="abstract hidden">
    <p>Some new tasks are trivial to learn, while others are essentially impossible; what determines
how easy it is to learn the structure of a given task? Similar to how our priors about visual
scenes demonstrably color our perception of the world, our priors about the structure of
tasks shape our learning, decision-making, and generalization abilities. Drawing inspiration
from the insights afforded to neuroscience by the characterization of visual priors, in this
dissertation, we strive to quantify priors over abstract structures. In particular, we focus on
graphs: the structure of interactions. 
<br />
<!-- <br /> -->
In Chapter 3, we describe the natural analogue of cumulants (e.g., mean, (co)variance,
skew, kurtosis) for graphs, building a hierarchical description based on local correlations
between an increasing number of connections. This provides a principled framework for
quantifying the propensity of a network to display arbitrary substructures, and allows one to
meaningfully compare networks of different sizes and edge densities.
<br />
<!-- <br /> -->
In Chapter 4, we analyze graph structure globally, via the dynamics of diffusion,
providing an algorithm that reduces a graph while preserving its large-scale structure.
Our framework analytically unifies two areas of research, namely graph sparsification
(removing edges) and graph coarsening (merging nodes), and is competitive with current
state-of-the-art algorithms.
<br />
<!-- <br /> -->
From a neuroscience perspective, we develop a novel method for quantifying human
priors over graphs (Chapters 2 and 3). In Chapter 5, we apply this method to graphical
representations of social and navigation tasks: two domains that have been relevant (over
evolutionary timescales) to our everyday life. We find that the resulting priors exhibit
non-trivial graphical structure. While some features appear to be general, such as the
preferred amount of sparsity as a function of graph size, other features appear to be
domain-specific, such as the preference for triadic closure in social interactions.
<br />
<!-- <br /> -->
Through the development of principled methods for analyzing network structure and
the use of an analytically tractable model of human learning on graphs, this work provides
useful tools that could cross-pollinate with other active areas of research, such as artificial
intelligence.
</p>
  </span>
  



<!--     
  <span class="abstract hidden">
    <p>Some new tasks are trivial to learn, while others are essentially impossible; what determines
how easy it is to learn the structure of a given task? Similar to how our priors about visual
scenes demonstrably color our perception of the world, our priors about the structure of
tasks shape our learning, decision-making, and generalization abilities. Drawing inspiration
from the insights afforded to neuroscience by the characterization of visual priors, in this
dissertation, we strive to quantify priors over abstract structures. In particular, we focus on
graphs: the structure of interactions. 
<br>
<br>
In Chapter 3, we describe the natural analogue of cumulants (e.g., mean, (co)variance,
skew, kurtosis) for graphs, building a hierarchical description based on local correlations
between an increasing number of connections. This provides a principled framework for
quantifying the propensity of a network to display arbitrary substructures, and allows one to
meaningfully compare networks of different sizes and edge densities.
<br>
<br>
In Chapter 4, we analyze graph structure globally, via the dynamics of diffusion,
providing an algorithm that reduces a graph while preserving its large-scale structure.
Our framework analytically unifies two areas of research, namely graph sparsification
(removing edges) and graph coarsening (merging nodes), and is competitive with current
state-of-the-art algorithms.
<br>
<br>
From a neuroscience perspective, we develop a novel method for quantifying human
priors over graphs (Chapters 2 and 3). In Chapter 5, we apply this method to graphical
representations of social and navigation tasks: two domains that have been relevant (over
evolutionary timescales) to our everyday life. We find that the resulting priors exhibit
non-trivial graphical structure. While some features appear to be general, such as the
preferred amount of sparsity as a function of graph size, other features appear to be
domain-specific, such as the preference for triadic closure in social interactions.
<br>
<br>
Through the development of principled methods for analyzing network structure and
the use of an analytically tractable model of human learning on graphs, this work provides
useful tools that could cross-pollinate with other active areas of research, such as artificial
intelligence.
</p>
  </span>
   -->

<!--      -->
</div>
</li></ol>

<h3 class="year">2019</h3>
<ol class="bibliography"><li>

<div id="grav2019aunifying">
  
    <span class="title">A Unifying Framework for Spectrum-Preserving Graph Sparsification and Coarsening</span>
    <span class="author">
      
        
          
            
              <em>Gecia Bravo-Hermsdorff*</em>
            
          
        
      
        
          
            
              
                and Lee M. Gunderson*
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Neural Information Processing Systems 33 (NeurIPS), </em>
    
    
      2019
    
    </span>
  

  <span class="links">

<!--    -->
  
    [<a class="quickabstract">Quick summary</a>]
  
  
      [<a class="abstract">Abstract</a>]
    
    [<a href="http://papers.neurips.cc/paper/8989-a-unifying-framework-for-spectrum-preserving-graph-sparsification-and-coarsening" target="_blank">URL</a>]
  
  
    [<a href="/assets/pdf/GraphReduction_NeurIPS2019.pdf" target="_blank">PDF</a>]
  
    
  
  
    [<a href="/assets/pdf/GraphReduction_NeurIPS2019_Poster.pdf" target="_blank">Poster</a>]
  
  
  
    [<a href="https://github.com/TheGravLab/A-Unifying-Framework-for-Spectrum-Preserving-Graph-Sparsification-and-Coarsening" target="_blank">Code</a>]
  
  
    [<a href="https://www.youtube.com/watch?v=xTAPZbQlq3A" target="_blank">Summary video (4m14s)</a>]
    
  
  [<a href="https://www.youtube.com/playlist?list=PLmfiQcz2q6d3sZutLri4ZAIDLqM_4K1p-" target="_blank">Reduction playlist</a>]
    
      
     
  </span>

  <!-- Hidden abstract block -->
    
  <span class="quickabstract hidden">
    <p>The deletion of edges (sparsification) and the merging of adjacent vertices (coarsening) are two common methods for reducing a graph. 
      We analytically unify these two operations using a single objective function based on the graph Laplacian pseudoinverse, 
      providing a principled algorithm that simultaneously sparsifies and coarsens a graph while preserving its large-scale structure.</p>
  </span>
  

   <span class="abstract hidden">
    <p>How might one “reduce” a graph? That is, generate a smaller graph that preserves
the global structure at the expense of discarding local details? There has been
extensive work on both graph sparsification (removing edges) and graph coarsening
(merging nodes, often by edge contraction); however, these operations are currently
treated separately. Interestingly, for a planar graph, edge deletion corresponds to
edge contraction in its planar dual (and more generally, for a graphical matroid
and its dual). Moreover, with respect to the dynamics induced by the graph
Laplacian (e.g., diffusion), deletion and contraction are physical manifestations
of two reciprocal limits: edge weights of zero and infinity, respectively. In this work, we
provide a unifying framework that captures both of these operations, allowing one
to simultaneously sparsify and coarsen a graph while preserving its large-scale
structure. The limit of infinite edge weight is rarely considered, as many classical
notions of graph similarity diverge. However, its algebraic, geometric, and physical
interpretations are reflected in the Laplacian pseudoinverse, which remains finite
in this limit. Motivated by this insight, we provide a probabilistic algorithm that
reduces graphs while preserving the Laplacian pseudoinverse, using an unbiased procedure that minimizes
its variance. We compare our algorithm with several existing sparsification and
coarsening algorithms using real-world datasets, and demonstrate that it more
accurately preserves the large-scale structure.</p>
  </span> 



<!--      -->

<!--      -->
</div>
</li>
<li>

<div id="bravohermsdorff2019gender">
  
    <span class="title">Gender and Collaboration Patterns in a Temporal Scientific Authorship Network</span>
    <span class="author">
      
        
          
            
              <em>Gecia Bravo-Hermsdorff</em>, 
            
          
        
      
        
          
            
              
                Valkyrie Felso, 
              
            
          
        
      
        
          
            
              
              Emily Ray, 
              
            
          
        
      
        
          
            
              
              Lee M. Gunderson, 
              
            
          
        
      
        
          
            
              
               Mary E. Helander, 
              
            
          
        
      
        
          
            
              
               Joana Maria, 
              
            
          
        
      
        
          
            
              
                and Yael Niv 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Applied Network Science, </em>
    
    
      4(1), 2019
    
    </span>
  

  <span class="links">

<!--    -->
  
    [<a class="quickabstract">Quick summary</a>]
  
      [<a class="abstract">Abstract</a>]
  
    [<a href="http://dx.doi.org/10.1007/s41109-019-0214-4" target="_blank">URL</a>]
  
  
    [<a href="/assets/pdf/INFORMS_paper.pdf" target="_blank">PDF</a>]
  
    
  
  
  
  
    
    
      
  
  [<a href="https://github.com/Gecia/INFORMS_TemporalGenderedAuthorshipNetwork" target="_blank">Dataset</a>]
     
  </span>

  <!-- Hidden abstract block -->
    
  <span class="quickabstract hidden">
    <p>We constructed a gender-labeled temporal bipartite graph of academic collaborations in the Institute for Operations Research and the Management Sciences (INFORMS) spanning over six decades. Employing two metrics based on the graph Laplacian which are sensitive to global connectivity, we analyze the relevance of gender in these collaboration patterns.</p>
  </span>
  

  <span class="abstract hidden">
    <p>One can point to a variety of historical milestones for gender equality in STEM (science,
technology, engineering, and mathematics), however, practical effects are incremental
and ongoing. It is important to quantify gender differences in subdomains of scientific
work in order to detect potential biases and monitor progress. In this work, we study
the relevance of gender in scientific collaboration patterns in the Institute for
Operations Research and the Management Sciences (INFORMS), a professional society
with sixteen peer-reviewed journals. Using their publication data from 1952 to 2016,
we constructed a large temporal bipartite network between authors and publications,
and augmented the author nodes with gender labels. We characterized differences in
several basic statistics of this network over time, highlighting how they have changed
with respect to relevant historical events. We find a steady increase in participation by
women (e.g., fraction of authorships by women and of new women authors) starting
around 1980. However, women still comprise less than 25% of the INFORMS society
and an even smaller fraction of authors with many publications. Moreover, we describe
a methodology for quantifying the structural role of an authorship with respect to the
overall connectivity of the network, using it to measure subtle differences between
authorships by women and by men. Specifically, as measures of structural importance
of an authorship, we use effective resistance and contraction importance, two measures
related to diffusion throughout a network. As a null model, we propose a degreepreserving temporal and geometric network model with emergent communities. Our
results suggest the presence of systematic differences between the collaboration
patterns of men and women that cannot be explained by only local statistics.</p>
  </span>  



<!--      -->

<!--      -->
</div>
</li>
<li>

<div id="bravohermsdorff2019hrf">
  
    <span class="title">Modeling the Hemodynamic Response Function for Prediction Errors in the Ventral Striatum</span>
    <span class="author">
      
        
          
            
              <em>Gecia Bravo-Hermsdorff</em> 
            
          
        
      
        
          
            
              
                and Yael Niv
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>bioRxiv, Cold Spring Harbor Laboratory, </em>
    
    
      2019
    
    </span>
  

  <span class="links">

<!--    -->
  
  
  
    [<a href="https://www.biorxiv.org/content/10.1101/800136v1" target="_blank">URL</a>]
  
  
    
  
  
  
  
    
    
      
     
  </span>

  <!-- Hidden abstract block -->
    

  



<!--      -->

<!--      -->
</div>
</li></ol>

<h3 class="year">2018</h3>
<ol class="bibliography"><li>

<div id="Hermsdorff_2018">
  
    <span class="title">Quantifying Humans’ Priors Over Graphical Representations of Tasks</span>
    <span class="author">
      
        
          
            
              <em>Gecia Bravo-Hermsdorff</em>,
            
          
        
      
        
          
            
              
                Talmo Pereira, 
              
            
          
        
      
        
          
            
              
                and Yael Niv
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Unifying Themes in Complex Systems IX. ICCS, </em>
    
    
      2018
    
    </span>
  

  <span class="links">

<!--    -->
  
  
  
    [<a href="https://link.springer.com/chapter/10.1007/978-3-319-96661-8_30" target="_blank">URL</a>]
  
  
    
  
  
  
  
    
    
      
     
  </span>

  <!-- Hidden abstract block -->
    

  



<!--      -->

<!--      -->
</div>
</li></ol>

<!-- <i>*denotes equal contribution.</i> -->

  </article>

  

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    2025 By Gecia Bravo-Hermsdorff -- gecia.bravo@gmail.com
    
  </div>

</footer>


<!-- <footer>

  <div class="wrapper">
    &copy; Copyright 2025 Gecia Bravo-Hermsdorff.
    # Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. # Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. # Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>.

    
  </div>

</footer>
 -->

    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>





<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/assets/css/academicons.min.css">


<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-XXXXXXXXX', 'auto');
ga('send', 'pageview');
</script>



  </body>

</html>
